{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-level Convolutional Neural Network for Sentence Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1.post2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "이제 앞서 만들어둔 word vector 를 이용하여 Yoon Kim, 2015 의 word - level CNN sentence classifier 를 만들어봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3279677\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "import numpy as np\n",
    "from navermovie_comments import load_comments_image\n",
    "\n",
    "class CommentsImage(Dataset):\n",
    "    def __init__(self, large=False, max_len=20):\n",
    "        super(CommentsImage, self).__init__()\n",
    "        # use only this tokenizer\n",
    "        tokenize = 'soynlp_unsup'\n",
    "\n",
    "        self.X, labels, self.idx_to_vocab = load_comments_image(\n",
    "            large=large, tokenize=tokenize, max_len=max_len)\n",
    "\n",
    "        # {0: negative, 1: neutral, 2: positive}\n",
    "        labels[np.where(labels <= 4)[0]] = 0\n",
    "        labels[np.where((labels > 4) & (labels < 8))] = 1\n",
    "        labels[np.where(8 <= labels)[0]] = 2\n",
    "        self.labels = labels\n",
    "\n",
    "        # transform numpy.ndarray to torch.tensor\n",
    "        self.X = torch.LongTensor(self.X)\n",
    "        self.labels = torch.LongTensor(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        y = self.labels[index]\n",
    "        return X, y\n",
    "\n",
    "\n",
    "large = True\n",
    "data_name = 'large' if large else 'small'\n",
    "comments_images = CommentsImage(large)\n",
    "\n",
    "print(len(comments_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`93234` 은 padding idx 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([17358,   149,    83,   324, 93234, 93234, 93234, 93234, 93234, 93234,\n",
      "        93234, 93234, 93234, 93234, 93234, 93234, 93234, 93234, 93234, 93234])\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "X, y = comments_images[2]\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 학습한 word2vec model 에서 word vectors 도 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93234, 100)\n",
      "93235\n"
     ]
    }
   ],
   "source": [
    "from navermovie_comments import load_trained_embedding\n",
    "\n",
    "word2vec_model = load_trained_embedding(data_name=data_name,\n",
    "    tokenize='soynlp_unsup', embedding='word2vec')\n",
    "\n",
    "wv = word2vec_model.wv.vectors\n",
    "\n",
    "print(wv.shape)\n",
    "print(len(comments_images.idx_to_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "padding 을 위한 zero vectors 를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93235, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_vector = np.zeros((1, wv.shape[1]), dtype=wv.dtype)\n",
    "wv = np.vstack([wv, zero_vector])\n",
    "wv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용할 parameter 몇 가지를 미리 정의합니다. \n",
    "\n",
    "Yoon Kim (2015) 의 논문에서는 각 크기의 kernel 마다 100 개의 CNN filter 를 만들었습니다. 이를 num_filters 에 저장해둡니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data related parameter\n",
    "num_words, embedding_dim = wv.shape\n",
    "num_filters = 100\n",
    "num_classes = np.unique(comments_images.labels.numpy()).shape[0]\n",
    "n_data = len(comments_images)\n",
    "\n",
    "# training related parameter\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader 를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "use_cuda = False\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    comments_images, batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "이번 예시는 아래의 reference 를 참고하였습니다. 유명한 모델들은 좋은 구현체들이 많습니다. 검색한 뒤, 본인의 스타일에 잘 맞는 코드를 이용하시면 좋습니다.\n",
    "\n",
    "reference : https://github.com/castorini/Castor/tree/master/kim_cnn\n",
    "\n",
    "Yoon Kim (2014) 에서는 (1) word embedding vectors 도 task 에 맞춰 학습하는 non-static version 과 (2) pretrained word embedding vectors 는 고정하는 static, (3) embedding vectors 를 random initialization 하거나 (4) static, non-static 을 합쳐쓰는 방법을 제안하였습니다. 두 종류의 word embedding vectors 를 함께 이용한다면 lookup 하는 과정에서 2 channel images 를 만들면 됩니다. 우리는 CNN 의 구조부터 익히기 위하여 static / non-static single channel 방식으로 모델을 만들어 봅니다.\n",
    "\n",
    "### init 함수\n",
    "\n",
    "init 에는 단어의 임베딩 벡터 차원의 크기, 단어 개수, 필터 개수, 클래스 개수를 각각 입력받습니다. 이들은 CNN 과 fully connected layer 의 input - output dimension 을 정의하는데 필요합니다. pretrained_wordvec 은 gensim 이나 다른 알고리즘으로 학습된 word embedding vectors 입니다. Dropout-ratio 는 dropout 하는 units 의 비율입니다. \n",
    "\n",
    "입력된 embedding_dim 과 num_words 가 pretrained word vector 의 크기와 같은지 확인하고, Embedding layer 를 만든 뒤, 이 값을 복사합니다.\n",
    "\n",
    "```python\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, parameters ... ):\n",
    "        # ...\n",
    "        n, m = pretrained_wordvec.shape\n",
    "        assert n == num_words and m == embedding_dim\n",
    "        self.embed = nn.Embedding(num_words, embedding_dim)\n",
    "        self.embed.weight.data.copy_(torch.from_numpy(pretrained_wordvec))\n",
    "```\n",
    "\n",
    "Yoon Kim, 2015 에서는 3, 4, 5 - gram 의 CNN filter 를 각각 100 개씩, 총 300 개의 filter 를 거친 뒤, dropout 과 fully connected layer 를 거쳐 softmax 로 classification 을 하였습니다. 우리는 한국어 데이터를 적용할 것이고, bigram 도 중요한 feature 이기 때문에 2, 3, 4 - gram 을 이용하는 CNN filter 를 만듭니다. Dropout layer 는 dropout_ratio 만 입력하면 됩니다. Fully connected layer 에 입력되는 값은 세 종류의 필터 각각 100 개씩, 총 300 개의 필터가 적용된 값입니다. (3 * num_filters, num_classes) 의 weight 를 지니는 fully connected layer 를 이용합니다.\n",
    "\n",
    "```python\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, parameters ... ):\n",
    "        # ...\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(2, embedding_dim))\n",
    "        self.conv2 = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(3, embedding_dim))\n",
    "        self.conv3 = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(4, embedding_dim))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "        self.fc1 = nn.Linear(3 * num_filters, num_classes)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward 함수 구현\n",
    "\n",
    "우리는 세 종류의 CNN filter 를 각각 self.conv1, self.conv2, self.conv3 으로 만들었습니다. forward 함수에 입력된 x 가 각각의 convolution layer 를 거치면 각각의 output 값이 만들어집니다. 이 값을 concatenation 하여 fully connected layer 에 입력하는 input 으로 만들 것입니다.\n",
    "\n",
    "일단 입력된 단어열에 Embedding lookup 을 한 뒤, resize 를 합니다. unsqueese 를 하는 이유는 앞서 말한 바와 같이 torch.nn.Embedding 에 적용된 값은 channel 의 개수가 지정되지 않기 때문입니다. unsqueeze(1) 을 통하여 out 의 format 을 (bath, sent_len, embed_dim) 에서 (batch, channel_input, sent_len, embed_dim) 으로 변환합니다.\n",
    "\n",
    "```python\n",
    "class TextCNN(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # ...\n",
    "    out = self.embed(x) # (batch, sent_len, embed_dim)\n",
    "    out = out.unsqueeze(1) # (batch, channel_input, sent_len, embed_dim)\n",
    "```\n",
    "\n",
    "Embedding lookup 을 통하여 만들어진 sentence image, out 을 세 종류의 CNN filter 에 적용합니다. 이 값을 list 에 모두 저장합니다. 각각의 CNN filter 가 적용된 값에 max pooling 을 적용합니다. 이 과정에서 squeeze, unsqueeze 를 왜 하는지 햇갈리시다면, 바로 위 chapter, applying CNN and pooling 을 다시 보시기 바랍니다. 현재 out 의 형태는 list of torch.Tensor 입니다. 이를 하나의 tensor 로 concatenation 합니다.\n",
    "\n",
    "```python\n",
    "class TextCNN(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # ...\n",
    "        out = [F.relu(self.conv1(out)).squeeze(3),\n",
    "               F.relu(self.conv2(out)).squeeze(3),\n",
    "               F.relu(self.conv3(out)).squeeze(3)]\n",
    "\n",
    "        out = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in out]\n",
    "        out = torch.cat(out, 1)\n",
    "```\n",
    "\n",
    "이 값을 dropout 을 거치고, fully connected layer 에 넣습니다.\n",
    "\n",
    "```python\n",
    "class TextCNN(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # ...\n",
    "        out = self.dropout(out)\n",
    "        logit = self.fc1(out) # (batch, target_size)\n",
    "\n",
    "        return logit\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, num_words, num_filters,\n",
    "                 num_classes, pretrained_wordvec, dropout_ratio=0.5):\n",
    "\n",
    "        super(TextCNN, self).__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(num_words, embedding_dim)\n",
    "\n",
    "        # check word embedding vector shape\n",
    "        n, m = pretrained_wordvec.shape\n",
    "        assert n == num_words and m == embedding_dim\n",
    "\n",
    "        self.embed.weight.data.copy_(torch.from_numpy(pretrained_wordvec))\n",
    "\n",
    "        # in_channels, out_channels, \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(2, embedding_dim), bias=False)\n",
    "        self.conv2 = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(3, embedding_dim), bias=False)\n",
    "        self.conv3 = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(4, embedding_dim), bias=False)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "        # three type convolution. each conv. has num_filters\n",
    "        self.fc1 = nn.Linear(3 * num_filters, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"x: sentence image\n",
    "                torch.LongTensor\"\"\"\n",
    "\n",
    "        out = self.embed(x) # (batch, sent_len, embed_dim)\n",
    "        out = out.unsqueeze(1) # (batch, channel_input, sent_len, embed_dim)\n",
    "\n",
    "        # three convolution filter\n",
    "        out = [F.relu(self.conv1(out)).squeeze(3),\n",
    "               F.relu(self.conv2(out)).squeeze(3),\n",
    "               F.relu(self.conv3(out)).squeeze(3)]\n",
    "\n",
    "        # 1 - max pooling for each conv\n",
    "        out = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in out]\n",
    "\n",
    "        # concatenation\n",
    "        out = torch.cat(out, 1)\n",
    "\n",
    "        # dropout\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        # fully connected neural network\n",
    "        logit = self.fc1(out) # (batch, target_size)\n",
    "\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 만듭니다. 그리고 print(model) 을 하면 직접 만든 모델의 구조가 출력됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextCNN(\n",
      "  (embed): Embedding(93235, 100)\n",
      "  (conv1): Conv2d(1, 100, kernel_size=(2, 100), stride=(1, 1), bias=False)\n",
      "  (conv2): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1), bias=False)\n",
      "  (conv3): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1), bias=False)\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (fc1): Linear(in_features=300, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = TextCNN(\n",
    "    embedding_dim,\n",
    "    num_words,\n",
    "    num_filters,\n",
    "    num_classes,\n",
    "    wv\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 함수는 이전의 document classification 예시와 비슷합니다. Data Loader 를 이용하였기 때문에 minibatch 단위로 학습이 됩니다. 매 epoch 마다 함수를 호출하는 형식으로 구현하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_func, optimizer, data_loader, epoch):\n",
    "\n",
    "    n_data = len(data_loader)\n",
    "    loss_sum = 0\n",
    "\n",
    "    for i, (X, y) in enumerate(data_loader):\n",
    "\n",
    "        # clean gradient buffer zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # predict\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # compute loss & back-propagation\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # cumulate loss\n",
    "        loss_sum += loss.data.numpy()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            loss_tmp = loss_sum / (i+1)\n",
    "            print('\\repoch = {}, batch = {}, training loss = {}'.format(\n",
    "                epoch, i, '%.3f' % loss_tmp), end='', flush=True)\n",
    "\n",
    "    print('\\repoch = {}, training loss = {}{}'.format(\n",
    "        epoch, '%.3f' % (loss_sum / (i+1)), ' '*40), flush=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 model 과 train 함수를 모두 만들었으니 실제로 모델을 학습합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## static vs non-static\n",
    "\n",
    "Yoon Kim, 2015 에서의 static model 은 pretrained word vector 를 Embedding 의 값으로 이용하고, 더는 학습을 하지 않는 것입니다. Word embedding layer 는 network 의 맨 앞의 layer 입니다. 이 layer 에 gradient 가 전달되지 않도록 지정하면 word vectors 는 바뀌지 않습니다. 이전의 PyTorch 0.3x 까지는 Variable 을 만들 때 gradient 설정을 하기도 하였습니다. 지금은 requires_grad 를 True, False 로 지정해줘도 됩니다.\n",
    "\n",
    "```python\n",
    "model = TextCNN(embedding_dim, num_words, num_filters, num_classes, wordvec)\n",
    "model.embed.weight.requires_grad = False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1, training loss = 0.451                                        \n",
      "epoch = 2, training loss = 0.431                                        \n",
      "epoch = 3, training loss = 0.424                                        \n",
      "epoch = 4, training loss = 0.421                                        \n",
      "epoch = 5, training loss = 0.418                                        \n",
      "\n",
      "epoch = 6, training loss = 0.416                                        \n",
      "epoch = 7, training loss = 0.414                                        \n",
      "epoch = 8, training loss = 0.412                                        \n",
      "epoch = 9, training loss = 0.411                                        \n",
      "epoch = 10, training loss = 0.410                                        \n",
      "\n",
      "epoch = 11, training loss = 0.409                                        \n",
      "epoch = 12, training loss = 0.408                                        \n",
      "epoch = 13, training loss = 0.408                                        \n",
      "epoch = 14, training loss = 0.407                                        \n",
      "epoch = 15, training loss = 0.406                                        \n",
      "\n",
      "epoch = 16, training loss = 0.405                                        \n",
      "epoch = 17, training loss = 0.405                                        \n",
      "epoch = 18, training loss = 0.405                                        \n",
      "epoch = 19, training loss = 0.404                                        \n",
      "epoch = 20, training loss = 0.403                                        \n",
      "\n",
      "epoch = 21, training loss = 0.403                                        \n",
      "epoch = 22, training loss = 0.402                                        \n",
      "epoch = 23, training loss = 0.402                                        \n",
      "epoch = 24, training loss = 0.402                                        \n",
      "epoch = 25, training loss = 0.401                                        \n",
      "\n",
      "epoch = 26, training loss = 0.401                                        \n",
      "epoch = 27, training loss = 0.401                                        \n",
      "epoch = 28, training loss = 0.400                                        \n",
      "epoch = 29, training loss = 0.400                                        \n",
      "epoch = 30, training loss = 0.400                                        \n",
      "\n",
      "epoch = 31, training loss = 0.400                                        \n",
      "epoch = 32, training loss = 0.399                                        \n",
      "epoch = 33, training loss = 0.399                                        \n",
      "epoch = 34, training loss = 0.399                                        \n",
      "epoch = 35, training loss = 0.398                                        \n",
      "\n",
      "epoch = 36, training loss = 0.399                                        \n",
      "epoch = 37, training loss = 0.398                                        \n",
      "epoch = 38, training loss = 0.398                                        \n",
      "epoch = 39, training loss = 0.398                                        \n",
      "epoch = 40, training loss = 0.398                                        \n",
      "\n",
      "epoch = 41, training loss = 0.397                                        \n",
      "epoch = 42, training loss = 0.397                                        \n",
      "epoch = 43, training loss = 0.397                                        \n",
      "epoch = 44, training loss = 0.397                                        \n",
      "epoch = 45, training loss = 0.396                                        \n",
      "\n",
      "epoch = 46, training loss = 0.396                                        \n",
      "epoch = 47, training loss = 0.397                                        \n",
      "epoch = 48, training loss = 0.396                                        \n",
      "epoch = 49, training loss = 0.396                                        \n",
      "epoch = 50, training loss = 0.396                                        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "# model = TextCNN(embedding_dim, num_words, num_filters, num_classes, wv)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.02\n",
    ")\n",
    "\n",
    "# do not update word embedding vector if static mode\n",
    "model.embed.weight.requires_grad = False\n",
    "\n",
    "for epoch in range(1, 50 + 1):\n",
    "    model = train(model, loss_func, optimizer, data_loader, epoch)\n",
    "    if epoch % 5 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1, training loss = 0.396                                        \n",
      "epoch = 2, training loss = 0.396                                        \n",
      "epoch = 3, training loss = 0.395                                        \n",
      "epoch = 4, training loss = 0.395                                        \n",
      "epoch = 5, training loss = 0.395                                        \n",
      "\n",
      "epoch = 6, training loss = 0.395                                        \n",
      "epoch = 7, training loss = 0.395                                        \n",
      "epoch = 8, training loss = 0.395                                        \n",
      "epoch = 9, training loss = 0.395                                        \n",
      "epoch = 10, training loss = 0.395                                        \n",
      "\n",
      "epoch = 11, training loss = 0.394                                        \n",
      "epoch = 12, training loss = 0.394                                        \n",
      "epoch = 13, training loss = 0.394                                        \n",
      "epoch = 14, training loss = 0.394                                        \n",
      "epoch = 15, training loss = 0.394                                        \n",
      "\n",
      "epoch = 16, training loss = 0.394                                        \n",
      "epoch = 17, training loss = 0.394                                        \n",
      "epoch = 18, training loss = 0.394                                        \n",
      "epoch = 19, training loss = 0.394                                        \n",
      "epoch = 20, training loss = 0.393                                        \n",
      "\n",
      "epoch = 21, training loss = 0.393                                        \n",
      "epoch = 22, training loss = 0.393                                        \n",
      "epoch = 23, training loss = 0.393                                        \n",
      "epoch = 24, training loss = 0.393                                        \n",
      "epoch = 25, training loss = 0.393                                        \n",
      "\n",
      "epoch = 26, training loss = 0.393                                        \n",
      "epoch = 27, training loss = 0.393                                        \n",
      "epoch = 28, training loss = 0.393                                        \n",
      "epoch = 29, training loss = 0.393                                        \n",
      "epoch = 30, training loss = 0.393                                        \n",
      "\n",
      "epoch = 31, training loss = 0.393                                        \n",
      "epoch = 32, training loss = 0.392                                        \n",
      "epoch = 33, training loss = 0.392                                        \n",
      "epoch = 34, training loss = 0.392                                        \n",
      "epoch = 35, training loss = 0.392                                        \n",
      "\n",
      "epoch = 36, training loss = 0.392                                        \n",
      "epoch = 37, training loss = 0.392                                        \n",
      "epoch = 38, training loss = 0.392                                        \n",
      "epoch = 39, batch = 14930, training loss = 0.391"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-0c9e4816103d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-8f06b61f39f2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loss_func, optimizer, data_loader, epoch)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# compute loss & back-propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 100 + 1):\n",
    "    model = train(model, loss_func, optimizer, data_loader, epoch)\n",
    "    if epoch % 5 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## performance\n",
    "\n",
    "학습 성능을 확인합니다. 모델링에 집중하기 위하여 학습 / 테스트 데이터를 나누는 것은 하지 않았습니다. 이번에 우리가 측정하는 것은 training accuracy 입니다. data loader 를 입력하고 데이터의 앞 부분의 batch 에 대해서만 정확도를 측정하였습니다.\n",
    "\n",
    "with torch.no_grad() 를 이용하면 이 때에는 gradient 계산을 하지 않습니다. model.eval 과 비슷한 역할을 합니다.\n",
    "\n",
    "```python\n",
    "with torch.no_grad():\n",
    "    # ...\n",
    "```\n",
    "\n",
    "model 을 이용하여 `y_pred` 를 계산하고, torch.max 를 이용하여 각 row 마다 column 기준으로 max 값을 찾습니다. score, predicated 는 (max, argmax) 와 같습니다. predicated 와 y 가 같은 개수를 계산하여 n_correct 에 누적합니다.\n",
    "\n",
    "```python\n",
    "for X, y in data_loader:\n",
    "    y_pred = model(X)\n",
    "    score, predicted = torch.max(y_pred.data, dim=1)\n",
    "    n_correct += (predicted == y).sum().numpy()\n",
    "```\n",
    "\n",
    "n_correct 의 개수를 batch number 와 batch size 의 곲으로 나눠주면 학습 정확도를 계산할 수 있습니다.\n",
    "\n",
    "```python\n",
    "accuracy = n_correct / (i * batch_size)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 batch was done\n",
      "accuracy = 0.84815625\n"
     ]
    }
   ],
   "source": [
    "def accuracy_test(model, data_loader, first_batch=1000):\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        for i, (X, y) in enumerate(data_loader):\n",
    "            if i == first_batch:\n",
    "                break\n",
    "            y_pred = model(X)\n",
    "            score, predicted = torch.max(y_pred.data, dim=1)\n",
    "            n_correct += (predicted == y).sum().numpy()\n",
    "            print('\\r%d batch ...' % i, end='')\n",
    "        print('\\r%d batch was done' % i)\n",
    "\n",
    "    accuracy = n_correct / (i * batch_size)\n",
    "    print('accuracy = {}'.format(accuracy))\n",
    "\n",
    "accuracy_test(model, data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 parameter 값은 torch.save 를 이용하여 저장할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = './textcnn_params.pt'\n",
    "# torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
